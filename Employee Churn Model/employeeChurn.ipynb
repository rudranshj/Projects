{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# import xgboost as xgb\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from time import strptime\n",
    "import sklearn\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import loadtxt\n",
    "# from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define functions to clean data, extract features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rudransh/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3063: DtypeWarning: Columns (2,3) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "dtrain=pd.read_csv('./train.csv')\n",
    "dtest=pd.read_csv('./test.csv') #for final prediction\n",
    "drating=pd.read_csv('./ratings.csv')\n",
    "drmk=pd.read_csv('./remarks.csv')\n",
    "drmk_supp=pd.read_csv('./remarks_supp_opp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(dtrain.head())\n",
    "# print('')\n",
    "# print(dtest.head())\n",
    "# print('')\n",
    "# print(drating.head())\n",
    "# print('')\n",
    "# print(drmk.head())\n",
    "# print('')\n",
    "# print(drmk_supp.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(dtrain))\n",
    "# print(len(dtest))\n",
    "# print(len(drating))\n",
    "# print(len(drmk))\n",
    "# print(len(drmk_supp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print((np.sum(dtrain['emp']>0)))\n",
    "# print((np.sum(dtest['emp']>0)))\n",
    "# print((np.sum(drating['emp']>0)))\n",
    "# print((np.sum(drmk['emp']>0))) #has fake values\n",
    "# print((np.sum(drmk_supp['emp']>0))) #has fake values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basicClean(df): # removes entries with emp<0 and generates a unique Id comp+emp \n",
    "    df=df[df['emp']>0].reset_index()\n",
    "    df['compemp']=df['comp']+df['emp'].apply(str)\n",
    "    return df\n",
    "\n",
    "def sep_train(df): #to separate features and labels\n",
    "    Y=df[['compemp','left']]\n",
    "    X=df[['id','emp','comp','lastratingdate']]\n",
    "    return X,Y\n",
    "# thought of additional features, like how many people leave particular company\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_dt(df): #same for test and train\n",
    "    df['lastratingdate']=df['lastratingdate'].str.replace('-','/')\n",
    "    df['lastratingdate']=pd.to_datetime(df['lastratingdate'],dayfirst=True)\n",
    "    return df\n",
    "def modif_drmk(df):\n",
    "    df['txtval']=df['txt'].str.len()\n",
    "    df['remarkDate']=df['remarkDate'].str.replace('-','/')\n",
    "    df['remarkDate']= pd.to_datetime(df['remarkDate'],dayfirst=True)\n",
    "    return df\n",
    "def modif_drmk_supp(df): #replace T/F (dtype=boolean) by 1 or 0\n",
    "    df.replace(to_replace=True, value=1, inplace=True)\n",
    "    df.replace(to_replace=False, value=0, inplace=True) \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dtest=basicClean(dtest)\n",
    "dtrain=basicClean(dtrain)\n",
    "drating=basicClean(drating)\n",
    "drmk=basicClean(drmk)\n",
    "drmk_supp=basicClean(drmk_supp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain=clean_dt(dtrain)\n",
    "dtest=clean_dt(dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "drmk=modif_drmk(drmk)\n",
    "drmk_supp=modif_drmk_supp(drmk_supp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(drmk_supp['remarkId'].unique())) #37178\n",
    "# print(len(drmk['remarkId'].unique())) #38993\n",
    "#  37178 and 38993. :(, there are some remarkIds, for which ther's no support value :("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(dtrain)/(len(dtrain['emp'].unique()))) #4.938375350140056"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(np.sum(dtrain.isnull()))\n",
    "# print(np.sum(drating.isnull()))\n",
    "# print(np.sum(drmk.isnull())) #it has nan values\n",
    "# print(np.sum(drmk_supp.isnull()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "221232\n",
      "38993\n",
      "324478\n",
      "\n",
      "37\n",
      "36\n",
      "34\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(drating['comp']))\n",
    "print(len(drmk['comp']))\n",
    "print(len(drmk_supp['comp']))\n",
    "print('')\n",
    "\n",
    "print(len(drating['comp'].unique()))\n",
    "print(len(drmk['comp'].unique()))\n",
    "print(len(drmk_supp['comp'].unique()))\n",
    "a=np.array(drating['comp'].unique())\n",
    "b=np.array(drmk['comp'].unique())\n",
    "c=np.array(drmk_supp['comp'].unique())\n",
    "A=np.concatenate((c,np.concatenate((a,b))))\n",
    "B=set(A)-set(a)\n",
    "len(B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## features\n",
    "###  drating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "drating=drating.sort_values(['compemp','Date'], ascending=[True, False])\n",
    "drating['const']=1\n",
    "# drating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rudransh/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/Users/rudransh/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/Users/rudransh/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "# 24Jul latest\n",
    "# RtComp_Dict comp:[noOfEmp,noOfRt,avgRt,lastRt Date]\n",
    "empCount_df=drating.drop_duplicates(subset='compemp',keep='first')\n",
    "empCount_df=empCount_df.groupby('comp').sum().reset_index()\n",
    "RtCount_df=drating.groupby('comp').sum().reset_index()\n",
    "RtAvg_df=drating.groupby('comp').mean().reset_index()\n",
    "RtDt_df=drating.drop_duplicates(subset='comp',keep='first')\n",
    "RtComp_Dict={}\n",
    "\n",
    "RtDt_df['Date']=RtDt_df['Date'].str.replace('-','/')\n",
    "RtDt_df['Date']=pd.to_datetime(RtDt_df['Date'],dayfirst=True)\n",
    "fromDate=min(RtDt_df['Date'])\n",
    "RtDt_df['Date']=(RtDt_df['Date']-fromDate).dt.days.astype(int)\n",
    "\n",
    "\n",
    "for i in range(len(RtDt_df)):\n",
    "    ar=[empCount_df.iloc[i]['const'],RtCount_df.iloc[i]['const'],round(RtAvg_df.iloc[i]['rating'],2),RtDt_df.iloc[i]['Date']]\n",
    "    RtComp_Dict[RtDt_df.iloc[i]['comp']]=ar\n",
    "# RtComp_Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rudransh/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n",
      "/Users/rudransh/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/Users/rudransh/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "# 24jul latest\n",
    "# RtEmp_Dict compemp: [noOfRatings, avgRating, recRating, lastDate]\n",
    "RtEmp_df=drating.groupby('compemp').sum().reset_index()\n",
    "# RtEmp_df\n",
    "RtEmpRec_df=drating.drop_duplicates(subset='compemp',keep='first')\n",
    "# RtEmpRec_df\n",
    "\n",
    "\n",
    "RtEmpRec_df['Date']=RtEmpRec_df['Date'].str.replace('-','/')\n",
    "RtEmpRec_df['Date']=pd.to_datetime(RtEmpRec_df['Date'],dayfirst=True)\n",
    "fromDate=min(RtEmpRec_df['Date'])\n",
    "RtEmpRec_df['Date']=(RtEmpRec_df['Date']-fromDate).dt.days.astype(int)\n",
    "\n",
    "\n",
    "RtEmp_Dict={} #compemp: [noOfRatings, avgRating,recRating, lastDate]\n",
    "for i in range(len(RtEmp_df)):\n",
    "    ar=[RtEmp_df.iloc[i]['const'],round((RtEmp_df.iloc[i]['rating']/RtEmp_df.iloc[i]['const']),2),RtEmpRec_df.iloc[i]['rating'],RtEmpRec_df.iloc[i]['Date']]\n",
    "    RtEmp_Dict[RtEmp_df.iloc[i]['compemp']]=ar\n",
    "# RtEmp_Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dremark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "drmk=drmk[['comp','compemp','txtval','remarkId','remarkDate']]\n",
    "# print(np.sum(drmk.isnull()))\n",
    "# print('')\n",
    "# print(drmk.describe())\n",
    "# print(\"______\")\n",
    "# print(len(drmk))\n",
    "drmk.dropna(axis=0,thresh=3,inplace=True)\n",
    "# print(np.sum(drmk.isnull()))\n",
    "# print(\"______\")\n",
    "# print(len(drmk))\n",
    "# drmk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## drmk_supp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drmk_supp\n",
    "# support + oppose =1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmk_supp_df=drmk_supp.groupby('remarkId').sum().reset_index()\n",
    "rmk_supp_df\n",
    "rmk_supp_Dict={} #remarkId:[support,oppose]\n",
    "for i in range(len(rmk_supp_df)):\n",
    "    ar=[rmk_supp_df.iloc[i]['support'],rmk_supp_df.iloc[i]['oppose']]\n",
    "    rmk_supp_Dict[rmk_supp_df.iloc[i]['remarkId']]=ar\n",
    "# rmk_supp_Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_supp_df=drmk_supp.groupby('compemp').sum().reset_index()\n",
    "# emp_supp_df\n",
    "emp_supp_Dict={} #compemp:[support, oppose]\n",
    "for i in range(len(emp_supp_df)):\n",
    "    ar=[emp_supp_df.iloc[i]['support'],emp_supp_df.iloc[i]['oppose']]\n",
    "    emp_supp_Dict[emp_supp_df.iloc[i]['compemp']]=ar\n",
    "# emp_supp_Dict\n",
    "# emp_supp_Dict compemp:[support, oppose]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drmk_supp\n",
    "compR=[]\n",
    "compempR=[]\n",
    "compempRDt=[]\n",
    "for i in range(len(drmk_supp)):\n",
    "    try:\n",
    "        compR.append(RtComp_Dict[drmk_supp.iloc[i]['comp']][2])\n",
    "    except KeyError:\n",
    "        compR.append(np.nan)\n",
    "    \n",
    "for i in range(len(drmk_supp)):\n",
    "    try:\n",
    "        compempR.append(RtEmp_Dict[drmk_supp.iloc[i]['compemp']][1])\n",
    "        compempRDt.append(RtEmp_Dict[drmk_supp.iloc[i]['compemp']][3])\n",
    "    except KeyError:\n",
    "        compempR.append(np.nan)\n",
    "        compempRDt.append(np.nan)\n",
    "# compempRDt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drmk_supp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS PART TAKES EXCEPTIONALLY LONG TIME TO PROCESS!\n",
    "drmk_supp['compR']=compR\n",
    "drmk_supp['compempR']=compempR\n",
    "drmk_supp['compempRDt']=compempRDt\n",
    "drmk_supp['compR*supp']=drmk_supp['compR']*drmk_supp['support']\n",
    "drmk_supp['compR*opp']=drmk_supp['compR']*drmk_supp['oppose']\n",
    "drmk_supp['compempR*supp']=drmk_supp['compempR']*drmk_supp['support']\n",
    "drmk_supp['compempR*opp']=drmk_supp['compempR']*drmk_supp['oppose']\n",
    "drmk_supp['compempDt*supp*compempR']=drmk_supp['compempR']*drmk_supp['support']\n",
    "drmk_supp['compempDt*opp*compempR']=drmk_supp['compempR']*drmk_supp['oppose']\n",
    "drmk_supp=drmk_supp.fillna(drmk_supp.mean())\n",
    "# drmk_supp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drmk_supp\n",
    "rmk_aux_df=drmk_supp.groupby('remarkId').mean().reset_index()\n",
    "# rmk_aux_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmk_aux_Dict={}\n",
    "for i in range(len(rmk_aux_df)):\n",
    "    rId=rmk_aux_df.iloc[i]['remarkId']\n",
    "    ar=[round(rmk_aux_df.iloc[i]['compR'],2),round(rmk_aux_df.iloc[i]['compempR'],2),round(rmk_aux_df.iloc[i]['compempR*supp'],2),round(rmk_aux_df.iloc[i]['compempR*opp'],2),round(rmk_aux_df.iloc[i]['compempDt*supp*compempR'],2),round(rmk_aux_df.iloc[i]['compempDt*opp*compempR'],2)]\n",
    "    rmk_aux_Dict[rId]=ar\n",
    "# rmk_aux_Dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## drmk and drmk_supp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "drmk=drmk.sort_values(['compemp','remarkDate'], ascending=[True, False])\n",
    "# drmk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "drmk=drmk.drop_duplicates(subset='remarkId', keep='first').reset_index()\n",
    "drmk\n",
    "supp_=[]\n",
    "opp_=[]\n",
    "supp_mean=[]\n",
    "\n",
    "aux_0=[]\n",
    "aux_1=[]\n",
    "aux_2=[]\n",
    "aux_3=[]\n",
    "aux_4=[]\n",
    "aux_5=[]\n",
    "\n",
    "for i in range(len(drmk)):\n",
    "    rId=drmk.iloc[i]['remarkId']\n",
    "    try:\n",
    "        ar=rmk_supp_Dict[rId]\n",
    "        supp_.append(ar[0])\n",
    "        opp_.append(ar[1])\n",
    "        supp_mean.append(ar[0]/(ar[0]+ar[1]))\n",
    "        \n",
    "        ar2=rmk_aux_Dict[rId]\n",
    "        aux_0.append(ar2[0])\n",
    "        aux_1.append(ar2[1])\n",
    "        aux_2.append(ar2[2])\n",
    "        aux_3.append(ar2[3])\n",
    "        aux_4.append(ar2[4])\n",
    "        aux_5.append(ar2[5])\n",
    "        \n",
    "        \n",
    "        \n",
    "    except KeyError:\n",
    "        supp_.append(np.nan)\n",
    "        opp_.append(np.nan)\n",
    "        supp_mean.append(np.nan)\n",
    "        \n",
    "        aux_0.append(np.nan)\n",
    "        aux_1.append(np.nan)\n",
    "        aux_2.append(np.nan)\n",
    "        aux_3.append(np.nan)\n",
    "        aux_4.append(np.nan)\n",
    "        aux_5.append(np.nan)\n",
    "        \n",
    "        \n",
    "        \n",
    "drmk['support']=supp_\n",
    "drmk['oppose']=opp_\n",
    "drmk['supp_mean']=supp_mean\n",
    "\n",
    "drmk['aux_0']=aux_0\n",
    "drmk['aux_1']=aux_1\n",
    "drmk['aux_2']=aux_2\n",
    "drmk['aux_3']=aux_3\n",
    "drmk['aux_4']=aux_4\n",
    "drmk['aux_5']=aux_5\n",
    "\n",
    "\n",
    "drmk=drmk.fillna(drmk.mean())\n",
    "# drmk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "drmk=drmk.round({'support':0,'oppose':0,'supp_mean':3,'aux_0':3,'aux_1':3,'aux_2':3,'aux_3':3,'aux_4':3,'aux_5':3})\n",
    "# drmk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "drmk['txt*supp']=drmk['txtval']*drmk['supp_mean']\n",
    "# drmk\n",
    "RmkComp_sum_df=drmk.groupby('comp').sum().reset_index()\n",
    "RmkComp_mean_df=drmk.groupby('comp').mean().reset_index()\n",
    "RmkComp_Dict={} # comp:[supp, opp, supp_mean, avg txtval, avg(txtval*supp_mean)]\n",
    "for i in range(len(RmkComp_sum_df)):\n",
    "    supp_total=RmkComp_sum_df.iloc[i]['support']\n",
    "    opp_total=RmkComp_sum_df.iloc[i]['oppose']\n",
    "    supp_mean_=round((supp_total/(supp_total+opp_total)),3)\n",
    "    avgtxtval=(RmkComp_mean_df.iloc[i]['txtval'])\n",
    "    \n",
    "    c_aux0=round(RmkComp_mean_df.iloc[i]['aux_0'],3)\n",
    "    c_aux1=round(RmkComp_mean_df.iloc[i]['aux_1'],3)\n",
    "    c_aux2=round(RmkComp_mean_df.iloc[i]['aux_2'],3)\n",
    "    c_aux3=round(RmkComp_mean_df.iloc[i]['aux_3'],3)\n",
    "    c_aux4=round(RmkComp_mean_df.iloc[i]['aux_4'],3)\n",
    "    c_aux5=round(RmkComp_mean_df.iloc[i]['aux_5'],3)\n",
    "    \n",
    "    ar=[supp_total,opp_total,supp_mean_,round(avgtxtval,0),round(avgtxtval*supp_mean_,2),c_aux0,c_aux1,c_aux2,c_aux3,c_aux4,c_aux5]\n",
    "    \n",
    "    RmkComp_Dict[RmkComp_sum_df.iloc[i]['comp']]=ar\n",
    "# RmkComp_Dict\n",
    "# RmkComp_Dict comp:[supp, opp, supp_mean, avg txtval, avg(txtval*supp_mean), more]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "RmkEmp_rec_Dict={} # RmkEmp_rec_Dict Compemp:[txtval, supp, opp, supp_mean, txt*supp, lastdate]\n",
    "RmkEmp_avg_Dict={} # RmkEmp_avg_Dict Compemp:[avgtxtval, supp, opp, supp_mean, avg(txt*supp), more]\n",
    "RmkEmp_rec_df=drmk.drop_duplicates(subset='compemp', keep='first').reset_index()\n",
    "RmkEmp_avg_df=drmk.groupby('compemp').mean().reset_index()\n",
    "# RmkEmp_avg_df\n",
    "\n",
    "\n",
    "# RmkEmp_rec_df['remarkDate']=RmkEmp_rec_df['remarkDate'].str.replace('-','/')\n",
    "RmkEmp_rec_df['remarkDate']=pd.to_datetime(RmkEmp_rec_df['remarkDate'],dayfirst=True)\n",
    "fromDate=min(RmkEmp_rec_df['remarkDate'])\n",
    "RmkEmp_rec_df['remarkDate']=(RmkEmp_rec_df['remarkDate']-fromDate).dt.days.astype(int)\n",
    "\n",
    "for i in range(len(RmkEmp_rec_df)):\n",
    "    ar1=[RmkEmp_rec_df.iloc[i]['txtval'],RmkEmp_rec_df.iloc[i]['support'],RmkEmp_rec_df.iloc[i]['oppose'],RmkEmp_rec_df.iloc[i]['supp_mean'],RmkEmp_rec_df.iloc[i]['txt*supp'],RmkEmp_rec_df.iloc[i]['remarkDate']]\n",
    "    e_aux0=round(RmkEmp_avg_df.iloc[i]['aux_0'],3)\n",
    "    e_aux1=round(RmkEmp_avg_df.iloc[i]['aux_1'],3)\n",
    "    e_aux2=round(RmkEmp_avg_df.iloc[i]['aux_2'],3)\n",
    "    e_aux3=round(RmkEmp_avg_df.iloc[i]['aux_3'],3)\n",
    "    e_aux4=round(RmkEmp_avg_df.iloc[i]['aux_4'],3)\n",
    "    e_aux5=round(RmkEmp_avg_df.iloc[i]['aux_5'],3)\n",
    "    \n",
    "    ar2=[round(RmkEmp_avg_df.iloc[i]['txtval'],0),round(RmkEmp_avg_df.iloc[i]['support'],2),round(RmkEmp_avg_df.iloc[i]['oppose'],2),round(RmkEmp_avg_df.iloc[i]['supp_mean'],3),round(RmkEmp_avg_df.iloc[i]['txt*supp'],3),e_aux0,e_aux1,e_aux2,e_aux3,e_aux4,e_aux5]\n",
    "    empId=RmkEmp_rec_df.iloc[i]['compemp']\n",
    "    RmkEmp_rec_Dict[empId]=ar1\n",
    "    RmkEmp_avg_Dict[empId]=ar2\n",
    "# RmkEmp_rec_Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RmkEmp_avg_Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# emp_supp_Dict compemp:[support, oppose]\n",
    "# RmkEmp_rec_Dict Compemp:[txtval, supp, opp, supp_mean, txt*supp, lastdate]\n",
    "# RmkEmp_avg_Dict Compemp:[avgtxtval, supp, opp, supp_mean, avg(txt*supp)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 aug : i have to append test and train data to extract a dictionary of last rating data\n",
    "\n",
    "d1=dtrain.copy(deep=True)\n",
    "d2=dtest.copy(deep=True)\n",
    "d1=d1[['comp','compemp','lastratingdate']]\n",
    "d2=d2[['comp','compemp','lastratingdate']]\n",
    "\n",
    "frames = [d1,d2]\n",
    "d_final = pd.concat(frames)\n",
    "\n",
    "d_final['Dt_num']=pd.to_datetime(d_final['lastratingdate'],dayfirst=True)\n",
    "fromDate=min(d_final['Dt_num'])\n",
    "d_final['Dt_num']=(d_final['Dt_num']-fromDate).dt.days.astype(int)\n",
    "d_final=d_final.sort_values(['comp','compemp'], ascending=[True, True])\n",
    "# d_final\n",
    "\n",
    "\n",
    "\n",
    "lRDt_emp_Dict={}\n",
    "aRDt_comp_Dict={}\n",
    "lRDt_emp_df=d_final.drop_duplicates(subset='compemp', keep='first').reset_index()\n",
    "aRDt_comp_df=d_final.groupby('comp').mean().reset_index()\n",
    "for i in range(len(lRDt_emp_df)):\n",
    "    lRDt_emp_Dict[lRDt_emp_df.iloc[i]['compemp']]=lRDt_emp_df.iloc[i]['Dt_num']\n",
    "for i in range(len(aRDt_comp_df)):\n",
    "    aRDt_comp_Dict[aRDt_comp_df.iloc[i]['comp']]=aRDt_comp_df.iloc[i]['Dt_num']\n",
    "# lRDt_emp_Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(lRDt_emp_Dict)  # 3505 initially\n",
    "# len(lRDt_emp_Dict) # now it is 4374 :) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# left ratio of company\n",
    "# dtrain\n",
    "\n",
    "# gives dict comp:[total left, left ratio]\n",
    "def feat_leftRatio(dtrain):\n",
    "    dtrain_left_sum=dtrain.groupby('comp').sum().reset_index()\n",
    "    dtrain_left_mean=dtrain.groupby('comp').mean().reset_index()\n",
    "    comp_left_Dict={}\n",
    "    for i in range(len(dtrain_left_sum)):\n",
    "        leftTotal=dtrain_left_sum.iloc[i]['left']\n",
    "        leftMean=dtrain_left_mean.iloc[i]['left']\n",
    "        comp_left_Dict[dtrain_left_sum.iloc[i]['comp']]=[leftTotal,round(leftMean,3)]\n",
    "    return comp_left_Dict\n",
    "comp_left_Dict=feat_leftRatio(dtrain)\n",
    "# comp_left_Dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(df):\n",
    "    Y=[]    \n",
    "    for i in range(len(df)):\n",
    "        Y.append(df.iloc[i]['left'])\n",
    "    return np.array(Y)\n",
    "\n",
    "    \n",
    "def extract_comp_feat(df,RtComp_Dict,RmkComp_Dict,comp_left_Dict,aRDt_comp_Dict):\n",
    "# RtComp_Dict comp:[noOfEmp,noOfRt,avgRt,lastRt Date]\n",
    "# RmkComp_Dict comp:[supp, opp, supp_mean, avg txtval, avg(txtval*supp_mean)]\n",
    "# comp_left_Dict comp:[total left, left ratio]   \n",
    "# RmkComp_Dict and RmkEmp_avg_Dict has got 6 more features. aux0 to aux5\n",
    "    \n",
    "    empCt=[]\n",
    "    noRt=[]\n",
    "    avgRt=[]\n",
    "    lastRtDt=[]\n",
    "    \n",
    "    supp=[]\n",
    "    opp=[]\n",
    "    supp_m=[]\n",
    "    txtval=[]\n",
    "    txtval_wt=[]\n",
    "    \n",
    "    left_tot=[]\n",
    "    left_rat=[]\n",
    "    \n",
    "    aRDt=[]\n",
    "    \n",
    "    c_aux_0=[]\n",
    "    c_aux_1=[]\n",
    "    c_aux_2=[]\n",
    "    c_aux_3=[]\n",
    "    c_aux_4=[]\n",
    "    c_aux_5=[]\n",
    "    \n",
    "    \n",
    "    for i in range(len(df)):\n",
    "        compId=df.iloc[i]['comp']\n",
    "        try:\n",
    "            aRDt.append(aRDt_comp_Dict[compId])\n",
    "        except KeyError:\n",
    "            aRDt.append(np.nan)\n",
    "        \n",
    "    \n",
    "    for i in range(len(df)):\n",
    "        compId=df.iloc[i]['comp']\n",
    "        try:\n",
    "            ar=RtComp_Dict[compId]\n",
    "            empCt.append(ar[0])\n",
    "            noRt.append(ar[1])\n",
    "            avgRt.append(ar[2])\n",
    "            lastRtDt.append(ar[3])  \n",
    "        except KeyError:\n",
    "            empCt.append(np.nan)\n",
    "            noRt.append(np.nan)\n",
    "            avgRt.append(np.nan)\n",
    "            lastRtDt.append(np.nan)  \n",
    "            \n",
    "    for i in range(len(df)):\n",
    "        compId=df.iloc[i]['comp']\n",
    "        try:\n",
    "            ar=RmkComp_Dict[compId]\n",
    "            supp.append(ar[0])\n",
    "            opp.append(ar[1])\n",
    "            supp_m.append(ar[2])\n",
    "            txtval.append(ar[3])\n",
    "            txtval_wt.append(ar[4])\n",
    "            c_aux_0.append(ar[5])\n",
    "            c_aux_1.append(ar[6])\n",
    "            c_aux_2.append(ar[7])\n",
    "            c_aux_3.append(ar[8])\n",
    "            c_aux_4.append(ar[9])\n",
    "            c_aux_5.append(ar[10])\n",
    " \n",
    "        except KeyError:\n",
    "            supp.append(np.nan)\n",
    "            opp.append(np.nan)\n",
    "            supp_m.append(np.nan)\n",
    "            txtval.append(np.nan)\n",
    "            txtval_wt.append(np.nan)\n",
    "            c_aux_0.append(np.nan)\n",
    "            c_aux_1.append(np.nan)\n",
    "            c_aux_2.append(np.nan)\n",
    "            c_aux_3.append(np.nan)\n",
    "            c_aux_4.append(np.nan)\n",
    "            c_aux_5.append(np.nan)\n",
    "            \n",
    "\n",
    "    for i in range(len(df)):\n",
    "        compId=df.iloc[i]['comp']\n",
    "        try:\n",
    "            ar=comp_left_Dict[compId]\n",
    "            left_tot.append(ar[0])\n",
    "            left_rat.append(ar[1])\n",
    "        except KeyError:\n",
    "            left_tot.append(np.nan)\n",
    "            left_rat.append(np.nan)\n",
    "     \n",
    "    return [empCt,\n",
    "            noRt,\n",
    "            avgRt,\n",
    "            lastRtDt,\n",
    "            supp,\n",
    "            opp,\n",
    "            supp_m,\n",
    "            txtval,\n",
    "            txtval_wt,\n",
    "            left_tot,\n",
    "            left_rat,\n",
    "            aRDt,\n",
    "            c_aux_0,\n",
    "            c_aux_1,\n",
    "            c_aux_2,\n",
    "            c_aux_3,\n",
    "            c_aux_4,\n",
    "            c_aux_5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_emp_feat(df,RtEmp_Dict,emp_supp_Dict,RmkEmp_rec_Dict,RmkEmp_avg_Dict,lRDt_emp_Dict):\n",
    "# RtEmp_Dict compemp: [noOfRatings, avgRating, recRating, lastDate]\n",
    "# emp_supp_Dict compemp:[support, oppose]\n",
    "# RmkEmp_rec_Dict Compemp:[txtval, supp, opp, supp_mean, txt*supp, lastdate]\n",
    "# RmkEmp_avg_Dict Compemp:[avgtxtval, supp, opp, supp_mean, avg(txt*supp)]\n",
    "# RmkComp_Dict and RmkEmp_avg_Dict has got 6 more features. aux0 to aux5   \n",
    "    \n",
    "    noOfRt=[]\n",
    "    avgRt=[]\n",
    "    recRt=[]\n",
    "    RtlastDt=[]\n",
    "    \n",
    "    emp_supp=[]\n",
    "    emp_opp=[]\n",
    "    \n",
    "    rec_txtval=[]\n",
    "    rec_supp=[]\n",
    "    rec_opp=[]\n",
    "    rec_supp_mean=[]\n",
    "    rec_txt_wt=[]\n",
    "    RklastDt=[]\n",
    "    \n",
    "    avg_txtval=[]\n",
    "    avg_supp=[]\n",
    "    avg_opp=[]\n",
    "    avg_supp_mean=[]\n",
    "    avg_txt_wt=[]\n",
    "    \n",
    "    lRDt=[]\n",
    "    \n",
    "    e_aux_0=[]\n",
    "    e_aux_1=[]\n",
    "    e_aux_2=[]\n",
    "    e_aux_3=[]\n",
    "    e_aux_4=[]\n",
    "    e_aux_5=[]\n",
    "    \n",
    "    \n",
    "    for i in range(len(df)):\n",
    "        empId=df.iloc[i]['compemp']\n",
    "        try:\n",
    "            lRDt.append(lRDt_emp_Dict[empId])\n",
    "        except KeyError:\n",
    "            lRDt.append(np.nan)\n",
    "    \n",
    "    \n",
    "    \n",
    "    for i in range(len(df)):\n",
    "        empId=df.iloc[i]['compemp']\n",
    "        try:\n",
    "            ar=RtEmp_Dict[empId]\n",
    "            noOfRt.append(ar[0])\n",
    "            avgRt.append(ar[1])\n",
    "            recRt.append(ar[2])\n",
    "            RtlastDt.append(ar[3])\n",
    "        except KeyError:\n",
    "            noOfRt.append(np.nan)\n",
    "            avgRt.append(np.nan)\n",
    "            recRt.append(np.nan)\n",
    "            RtlastDt.append(np.nan)\n",
    "            \n",
    "    for i in range(len(df)):\n",
    "        empId=df.iloc[i]['compemp']\n",
    "        try:\n",
    "            ar=emp_supp_Dict[empId]\n",
    "            emp_supp.append(ar[0])\n",
    "            emp_opp.append(ar[1])\n",
    "        except KeyError:\n",
    "            emp_supp.append(np.nan)\n",
    "            emp_opp.append(np.nan)\n",
    "    \n",
    "    for i in range(len(df)):\n",
    "        empId=df.iloc[i]['compemp']\n",
    "        try:\n",
    "            ar=RmkEmp_rec_Dict[empId]\n",
    "            rec_txtval.append(ar[0])\n",
    "            rec_supp.append(ar[1])\n",
    "            rec_opp.append(ar[2])\n",
    "            rec_supp_mean.append(ar[3])\n",
    "            rec_txt_wt.append(ar[4])\n",
    "            RklastDt.append(ar[5])\n",
    "        except KeyError:\n",
    "            rec_txtval.append(np.nan)\n",
    "            rec_supp.append(np.nan)\n",
    "            rec_opp.append(np.nan)\n",
    "            rec_supp_mean.append(np.nan)\n",
    "            rec_txt_wt.append(np.nan)\n",
    "            RklastDt.append(np.nan)\n",
    "    \n",
    "    for i in range(len(df)):\n",
    "        empId=df.iloc[i]['compemp']\n",
    "        try:\n",
    "            ar=RmkEmp_avg_Dict[empId]\n",
    "            avg_txtval.append(ar[0])\n",
    "            avg_supp.append(ar[1])\n",
    "            avg_opp.append(ar[2])\n",
    "            avg_supp_mean.append(ar[3])\n",
    "            avg_txt_wt.append(ar[4])\n",
    "            e_aux_0.append(ar[5])\n",
    "            e_aux_1.append(ar[6])\n",
    "            e_aux_2.append(ar[7])\n",
    "            e_aux_3.append(ar[8])\n",
    "            e_aux_4.append(ar[9])\n",
    "            e_aux_5.append(ar[10])\n",
    "            \n",
    "        except KeyError:\n",
    "            avg_txtval.append(np.nan)\n",
    "            avg_supp.append(np.nan)\n",
    "            avg_opp.append(np.nan)\n",
    "            avg_supp_mean.append(np.nan)\n",
    "            avg_txt_wt.append(np.nan)\n",
    "            e_aux_0.append(np.nan)\n",
    "            e_aux_1.append(np.nan)\n",
    "            e_aux_2.append(np.nan)\n",
    "            e_aux_3.append(np.nan)\n",
    "            e_aux_4.append(np.nan)\n",
    "            e_aux_5.append(np.nan)\n",
    "    \n",
    "    return [noOfRt,\n",
    "            avgRt,\n",
    "            recRt,\n",
    "            RtlastDt,\n",
    "            emp_supp,\n",
    "            emp_opp,\n",
    "            rec_txtval,\n",
    "            rec_supp,\n",
    "            rec_opp,\n",
    "            rec_supp_mean,\n",
    "            rec_txt_wt,\n",
    "            RklastDt,\n",
    "            avg_txtval,\n",
    "            avg_supp,\n",
    "            avg_opp,\n",
    "            avg_supp_mean,\n",
    "            avg_txt_wt,\n",
    "            lRDt,\n",
    "            e_aux_0,\n",
    "            e_aux_1,\n",
    "            e_aux_2,\n",
    "            e_aux_3,\n",
    "            e_aux_4,\n",
    "            e_aux_5]\n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label=get_label(dtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basicFeat(df):\n",
    "    compFeat=extract_comp_feat(df,RtComp_Dict,RmkComp_Dict,comp_left_Dict,aRDt_comp_Dict)\n",
    "    empFeat=extract_emp_feat(df,RtEmp_Dict,emp_supp_Dict,RmkEmp_rec_Dict,RmkEmp_avg_Dict,lRDt_emp_Dict)\n",
    "    feat_df=pd.DataFrame({'empCt':compFeat[0],\n",
    "                          'noRt':compFeat[1],\n",
    "                          'avgRt':compFeat[2],\n",
    "                          'lastRtDt':compFeat[3],\n",
    "                          'supp':compFeat[4],\n",
    "                          'opp':compFeat[5],\n",
    "                          'supp_m':compFeat[6],\n",
    "                          'txtval':compFeat[7],\n",
    "                          'txtval_wt':compFeat[8],\n",
    "                          'left_tot':compFeat[9],\n",
    "                          'left_rat':compFeat[10],\n",
    "                          'ARtDt':compFeat[11],\n",
    "                            'c_aux_0':compFeat[12],\n",
    "                            'c_aux_1':compFeat[13],\n",
    "                            'c_aux_2':compFeat[14],\n",
    "                            'c_aux_3':compFeat[15],\n",
    "                            'c_aux_4':compFeat[16],\n",
    "                            'c_aux_5':compFeat[17],\n",
    "                          'noOfRt':empFeat[0],\n",
    "                          'avgRt':empFeat[1],\n",
    "                          'recRt':empFeat[2],\n",
    "                          'RtlastDt':empFeat[3],\n",
    "                          'emp_supp':empFeat[4],\n",
    "                          'emp_opp':empFeat[5],\n",
    "                          'rec_txtval':empFeat[6],\n",
    "                          'rec_supp':empFeat[7],\n",
    "                          'rec_opp':empFeat[8],\n",
    "                          'rec_supp_mean':empFeat[9],\n",
    "                          'rec_txt_wt':empFeat[10],\n",
    "                          'RklastDt':empFeat[11],\n",
    "                          'avg_txtval':empFeat[12],\n",
    "                          'avg_supp':empFeat[13],\n",
    "                          'avg_opp':empFeat[14],\n",
    "                          'avg_supp_mean':empFeat[15],\n",
    "                          'avg_txt_wt':empFeat[16],\n",
    "                          'lRDt':empFeat[17],\n",
    "#                          'e_aux_0':empFeat[18],\n",
    "#                             'e_aux_1':empFeat[19],\n",
    "#                             'e_aux_2':empFeat[20],\n",
    "#                             'e_aux_3':empFeat[21],\n",
    "#                             'e_aux_4':empFeat[22],\n",
    "#                             'e_aux_5':empFeat[23]\n",
    "                         })     \n",
    "    \n",
    "    feat_df.fillna(feat_df.mean(),inplace=True)\n",
    "    feat_df['left_tot']=feat_df['left_tot']*feat_df['left_tot']\n",
    "    feat_df['left_rat']=feat_df['left_rat']\n",
    "    feat_df['emp_rating*txtval']=feat_df['avgRt']*feat_df['avg_txtval']\n",
    "    feat_df['emp_rating*txtval_wt']=feat_df['avgRt']*feat_df['avg_txt_wt']\n",
    "    feat_df['emp_raing*mean_supp']=feat_df['avgRt']*feat_df['avg_supp_mean']\n",
    "    feat_df['comp_rating*txtval']=feat_df['avgRt']*feat_df['txtval']\n",
    "    feat_df['comp_rating*txtval_wt']=feat_df['avgRt']*feat_df['txtval_wt']\n",
    "    feat_df['comp_raing*mean_supp']=feat_df['avgRt']*feat_df['supp_m']\n",
    "    \n",
    "    feat_df['comp_raing*mean_supp']=feat_df['comp_raing*mean_supp']*100\n",
    "    feat_df = feat_df.round({'lastRtDt': 0,'RtlastDt':0,'RklastDt':0,'avg_supp':2,'avg_opp':2,'avg_supp_mean':3,\n",
    "                            'avg_txt_wt':0,'emp_rating*txtval':1,'emp_rating*txtval_wt':2,'emp_raing*mean_supp':2,\n",
    "                            'comp_raing*mean_supp':3,})\n",
    "    \n",
    "    return feat_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feat_df=basicFeat(dtrain)\n",
    "test_feat_df=basicFeat(dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_feat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_feat_df['lRDt'] i messed up here change the dictionary man all 797.307 values\n",
    "# test_feat_df['lRDt'] #yup its good now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_analy=basicFeat(dtrain)\n",
    "train_analy['left']=train_label\n",
    "# train_analy=train_analy.groupby('left').mean().reset_index()\n",
    "# train_analy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_analy=train_analy.groupby('left').mean().reset_index()\n",
    "# train_analy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_csv(Y_pred,filename):\n",
    "    output=pd.DataFrame({'id':dtest['id'],'left':Y_pred})\n",
    "    output.to_csv(filename,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wt_acc(Y_true,Y_pred):\n",
    "    w=[1,5] # weight for class 0 is 1 for class 1 is 5\n",
    "    n=len(Y_pred)\n",
    "    num=0\n",
    "    den=0\n",
    "    for i in range(len(Y_pred)):\n",
    "        den = den + w[Y_true[i]]\n",
    "        if Y_pred[i]==Y_true[i]:\n",
    "            num = num + w[Y_pred[i]]\n",
    "    return num/(den)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conf(Y_val, Y_val_pred):\n",
    "#     print(np.sum(Y_val==1))\n",
    "#     print(np.sum(Y_val_pred==1))\n",
    "\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    cm = confusion_matrix(Y_val, Y_val_pred)\n",
    "    import seaborn as sns\n",
    "    import matplotlib.pyplot as plt     \n",
    "\n",
    "    ax= plt.subplot()\n",
    "    sns.heatmap(cm, annot=True, ax = ax) #annot=True to annotate cells\n",
    "\n",
    "    # labels, title and ticks\n",
    "    ax.set_xlabel('Predicted labels')\n",
    "    ax.set_ylabel('True labels') \n",
    "    ax.set_title('Confusion Matrix')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_total=train_feat_df.to_numpy()\n",
    "Y_train_total=get_label(dtrain)\n",
    "X_test=test_feat_df.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the set to training and validation, set accuracy criteria\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train_total, Y_train_total, test_size=0.33, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(test_feat_df.var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "scorer = sklearn.metrics.make_scorer(wt_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params in use:\n",
      "\n",
      "{'bootstrap': True,\n",
      " 'ccp_alpha': 0.0,\n",
      " 'class_weight': None,\n",
      " 'criterion': 'gini',\n",
      " 'max_depth': None,\n",
      " 'max_features': 'auto',\n",
      " 'max_leaf_nodes': None,\n",
      " 'max_samples': None,\n",
      " 'min_impurity_decrease': 0.0,\n",
      " 'min_impurity_split': None,\n",
      " 'min_samples_leaf': 1,\n",
      " 'min_samples_split': 2,\n",
      " 'min_weight_fraction_leaf': 0.0,\n",
      " 'n_estimators': 100,\n",
      " 'n_jobs': None,\n",
      " 'oob_score': False,\n",
      " 'random_state': 5,\n",
      " 'verbose': 0,\n",
      " 'warm_start': False}\n",
      "{'bootstrap': [True, False],\n",
      " 'class_weight': [{0: 1, 1: 7}],\n",
      " 'criterion': ['entropy', 'gini'],\n",
      " 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None],\n",
      " 'max_features': ['auto', 'sqrt'],\n",
      " 'min_impurity_decrease': [0.0001],\n",
      " 'min_samples_leaf': [1, 2, 4],\n",
      " 'min_samples_split': [2, 5, 10],\n",
      " 'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]}\n",
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   27.1s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  3.7min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score=nan,\n",
       "                   estimator=RandomForestClassifier(bootstrap=True,\n",
       "                                                    ccp_alpha=0.0,\n",
       "                                                    class_weight=None,\n",
       "                                                    criterion='gini',\n",
       "                                                    max_depth=None,\n",
       "                                                    max_features='auto',\n",
       "                                                    max_leaf_nodes=None,\n",
       "                                                    max_samples=None,\n",
       "                                                    min_impurity_decrease=0.0,\n",
       "                                                    min_impurity_split=None,\n",
       "                                                    min_samples_leaf=1,\n",
       "                                                    min_samples_split=2,\n",
       "                                                    min_weight_fraction_leaf=0.0,\n",
       "                                                    n_estimators=100,\n",
       "                                                    n_jobs...\n",
       "                                        'max_depth': [10, 20, 30, 40, 50, 60,\n",
       "                                                      70, 80, 90, 100, 110,\n",
       "                                                      None],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_impurity_decrease': [0.0001],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [200, 400, 600, 800,\n",
       "                                                         1000, 1200, 1400, 1600,\n",
       "                                                         1800, 2000]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=5, refit=True,\n",
       "                   return_train_score=False, scoring=make_scorer(wt_acc),\n",
       "                   verbose=2)"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(random_state = 5)\n",
    "from pprint import pprint\n",
    "\n",
    "print('Params in use:\\n')\n",
    "pprint(rf.get_params())\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "\n",
    "max_features = ['auto', 'sqrt']\n",
    "\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "\n",
    "min_samples_split = [2, 5, 10]\n",
    "\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "min_impurity_decrease=[0.0001]\n",
    "bootstrap = [True, False]\n",
    "\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'class_weight':[{0:1,1:7}],\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'criterion':['entropy','gini'],\n",
    "               'bootstrap': bootstrap,\n",
    "              'min_impurity_decrease':min_impurity_decrease}\n",
    "pprint(random_grid)\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=5, n_jobs = -1,scoring=scorer)\n",
    "\n",
    "rf_random.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 600,\n",
       " 'min_samples_split': 10,\n",
       " 'min_samples_leaf': 4,\n",
       " 'min_impurity_decrease': 0.0001,\n",
       " 'max_features': 'auto',\n",
       " 'max_depth': 20,\n",
       " 'criterion': 'entropy',\n",
       " 'class_weight': {0: 1, 1: 7},\n",
       " 'bootstrap': False}"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr=rf_random.best_params_\n",
    "pr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'RandomForestClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-2696f5520d4e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# standard one\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m rfc=RandomForestClassifier(n_estimators=1000,min_samples_split=10,criterion='entropy',\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mmin_samples_leaf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                            random_state=5,bootstrap=True, min_impurity_decrease=0.0001)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'RandomForestClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "# above code for validation gives different answers at diff times,\n",
    "# below is implementation of one of them\n",
    "\n",
    "# standard one\n",
    "rfc=RandomForestClassifier(n_estimators=1000,min_samples_split=10,criterion='entropy',\n",
    "    min_samples_leaf=4,max_features='auto',max_depth=50,class_weight={0:1,1:200},\n",
    "                           random_state=5,bootstrap=True, min_impurity_decrease=0.0001)\n",
    "\n",
    "rfc.fit(X_train, Y_train)\n",
    "\n",
    "Y_val_pred_rfc=rfc.predict(X_val)\n",
    "\n",
    "print(\"weighted accuracy is: \"+str(wt_acc(Y_val,Y_val_pred_rfc)))\n",
    "\n",
    "print(\"length of Y_val\", len(Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                       class_weight={0: 1, 1: 200}, criterion='entropy',\n",
       "                       max_depth=50, max_features='auto', max_leaf_nodes=None,\n",
       "                       max_samples=None, min_impurity_decrease=0.0001,\n",
       "                       min_impurity_split=None, min_samples_leaf=4,\n",
       "                       min_samples_split=10, min_weight_fraction_leaf=0.0,\n",
       "                       n_estimators=1000, n_jobs=None, oob_score=False,\n",
       "                       random_state=5, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.fit(X_train_total,Y_train_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3526\n",
      "3526\n",
      "1164\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train_total))\n",
    "print(592+2934)\n",
    "print(len(X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 28 and 78 and 0.889"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred=rfc.predict(X_test)\n",
    "save_csv(Y_pred,'lastandFinal.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
